{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkripsiCNN_Klasifkasi_Kulit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK30m7ICZxop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4kVUJjVaNzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = \"/content/drive/My Drive/Colab Notebooks/dataset_kulit_skripsi.zip\"\n",
        "\n",
        "print(train_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI5L58tjaQe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H684PLCvTlHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zipfile.ZipFile(train_file, 'r') as z:\n",
        "    z.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L0lCwGUUPLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(file_path):\n",
        "    return plt.imread(file_path)\n",
        "\n",
        "def extract_label(file_name):\n",
        "    if \"domba\" in file_name:\n",
        "        return 0\n",
        "    elif  \"imitasi\" in file_name:\n",
        "        return 1\n",
        "    elif \"kambing\" in file_name:\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "train_path = \"./dataset_kulit_skripsi/\"\n",
        "image_files = os.listdir(train_path)\n",
        "\n",
        "class_name = ['Domba', 'Imitasi', 'Kambing', 'Sapi']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrhNS-7bWL_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_x = [load_image(train_path + file) for file in image_files]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_00p9-OhVyqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = [extract_label(file) for file in image_files]\n",
        "\n",
        "print(type(train_images_x))\n",
        "print(type(train_labels))\n",
        "print('train_labels =', train_labels)\n",
        "print(len(train_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfSX5EiVaT9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(train_images[1])\n",
        "\n",
        "# print('Gambar', train_labels[1], '=', class_name[train_labels[1]])\n",
        "# print('Shape =', train_images[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDjf8xA3aWL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_grayscale(img, side=448):\n",
        "    min_side = min(img.shape[0], img.shape[1])\n",
        "    img = img[:min_side, :min_side]\n",
        "    img = cv2.resize(img, (side, side))\n",
        "    \n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    return img_gray / 255.0\n",
        "\n",
        "def preprocess_adaptive_gaussian(gambar, side=448):\n",
        "    min_side = min(gambar.shape[0], gambar.shape[1])\n",
        "    gambar = gambar[:min_side, :min_side]\n",
        "    gambar = cv2.resize(gambar, (side, side))\n",
        "    gambar = cv2.cvtColor(gambar, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    img_gaussian = cv2.adaptiveThreshold(gambar, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
        "\n",
        "    return img_gaussian / 255.0\n",
        "\n",
        "# def preprocess_otsu_threshold(gambar2, side=384):\n",
        "#     min_side = min(gambar2.shape[0], gambar2.shape[1])\n",
        "#     gambar2 = gambar2[:min_side, :min_side]\n",
        "#     gambar2 = cv2.resize(gambar2, (side, side))\n",
        "#     gambar2 = cv2.cvtColor(gambar2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     _, citra_otsu = cv2.threshold(gambar2, 125, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "#     return citra_otsu / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndHIsPqUsN_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# var = (preprocess_grayscale(train_images_x[0]))\n",
        "# display(pd.DataFrame(var))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAUvg9KCaXNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(preprocess_adaptive_gaussian(train_images_x[21])))\n",
        "print(type(train_images_x[21]))\n",
        "print(type(train_images_x))\n",
        "print(len(train_images_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM2YPfXAaXwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in range(len(train_images_x)):\n",
        "  train_images_x[x] = preprocess_grayscale(train_images_x[x])\n",
        "\n",
        "print(len(train_images_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq_3ucq8uxlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_y = [load_image(train_path + file) for file in image_files]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ajuyxHvasM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in range(len(train_images_y)):\n",
        "  train_images_y[x] = preprocess_adaptive_gaussian(train_images_y[x])\n",
        "\n",
        "print(len(train_images_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_gS25bJa25v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(train_images_x))\n",
        "print(type(train_images_y))\n",
        "\n",
        "temp_train_images = list()\n",
        "temp_train_labels = list()\n",
        "\n",
        "temp_train_images.extend(train_images_x)\n",
        "temp_train_images.extend(train_images_y)\n",
        "\n",
        "temp_train_labels.extend(train_labels)\n",
        "temp_train_labels.extend(train_labels)\n",
        "\n",
        "print(type(temp_train_images))\n",
        "print(len(temp_train_images))\n",
        "print(len(temp_train_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w2w1y_sa4qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_train_images = np.array(temp_train_images)\n",
        "\n",
        "temp_train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyxIVorYa9fE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Citra Grayscale\")\n",
        "plt.imshow(temp_train_images[8], cmap=\"gray\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"Citra Gaussian\")\n",
        "plt.imshow(temp_train_images[648], cmap=\"gray\")\n",
        "\n",
        "print('Gambar', temp_train_labels[8], '=', class_name[temp_train_labels[8]])\n",
        "print('Shape =', temp_train_images[8].shape)\n",
        "\n",
        "print('\\nGambar', temp_train_labels[648], '=', class_name[temp_train_labels[648]])\n",
        "print('Shape =', temp_train_images[648].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4DNHLnea-aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(temp_train_images[0].shape)\n",
        "\n",
        "print(len(temp_train_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2y2bMzJa-rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_train_images = np.expand_dims(temp_train_images, axis=-1)\n",
        "temp_train_labels = np.array(temp_train_labels)\n",
        "\n",
        "print(temp_train_images.shape, 'train_images')\n",
        "print(temp_train_labels.shape, 'train_labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9LQKSQ5a-7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(temp_train_images, temp_train_labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwf3E30Wa_QW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(temp_train_images.shape, 'train_images')\n",
        "print(temp_train_labels.shape, 'train_labels')\n",
        "print('---------------------------------')\n",
        "\n",
        "temp_train_images = X_train\n",
        "temp_train_labels = y_train\n",
        "val_images = X_test\n",
        "val_labels = y_test\n",
        "\n",
        "# test_images = X_test\n",
        "# test_labels = y_test\n",
        "\n",
        "print(temp_train_images.shape[0], 'train_images')\n",
        "print(val_images.shape[0], 'validation data\\n')\n",
        "\n",
        "print(temp_train_labels.shape[0], 'train_labels')\n",
        "print(val_labels.shape[0], 'validation labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-66Tp6TZgu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(temp_train_images.shape)\n",
        "print(temp_train_labels.shape)\n",
        "print(val_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfBJ9vj0EIbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "\n",
        "df = pd.DataFrame(val_labels)\n",
        "\n",
        "df.columns=[\"Nilai\"]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if row['Nilai'] == 0:\n",
        "    df.loc[index, 'Jenis'] = 'Domba'\n",
        "  elif row ['Nilai'] == 1:\n",
        "    df.loc[index, 'Jenis'] = 'Imitasi'\n",
        "  elif row ['Nilai'] == 2:\n",
        "    df.loc[index, 'Jenis'] = 'Kambing'\n",
        "  else:\n",
        "    df.loc[index, 'Jenis'] = \"Sapi\"\n",
        "        \n",
        "df[['Nilai','Jenis']]\n",
        "df.to_csv('test_data.csv')\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2MFC3sUbFh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(val_images[99])\n",
        "\n",
        "print('Gambar', val_labels[0], '=', class_name[val_labels[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb54IIfkbFzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorboard\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "import datetime\n",
        "\n",
        "print(\"Tensorflow:\", tf.__version__, \"\\n\")\n",
        "print(\"Keras:\", keras.__version__, \"\\n\")\n",
        "print(\"OpenCV:\", cv2.__version__, \"\\n\")\n",
        "print(\"Tensorboard:\", tensorboard.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK51gQZRoM71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_train_images.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZVbBIeNxGzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Clear any logs from tensoboard previous runs\n",
        "# !rm -rf ./logs/ \n",
        "\n",
        "# layers = [\n",
        "#     tf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu, input_shape = temp_train_images.shape[1:]),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "#     tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "#     tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "#     tf.keras.layers.Conv2D(filters=96, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "#     tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "#     tf.keras.layers.Conv2D(filters=160, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "#     # tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "#     tf.keras.layers.Flatten(),\n",
        "\n",
        "#     tf.keras.layers.Dense(units=32, activation=tf.keras.activations.relu),\n",
        "\n",
        "#     tf.keras.layers.Dense(units=4, activation=tf.keras.activations.softmax)\n",
        "# ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJzxgNcEALAA",
        "colab": {}
      },
      "source": [
        "# Clear any logs from tensoboard previous runs\n",
        "!rm -rf ./logs/ \n",
        "\n",
        "layers = [\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu, input_shape = temp_train_images.shape[1:]),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=96, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=160, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=192, kernel_size=(3, 3), strides=(1,1), padding=\"same\", activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(units=128, activation=tf.keras.activations.relu),\n",
        "\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(units=4, activation=tf.keras.activations.softmax)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNvCbCDOstmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential(layers)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7fjP-A0wyMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model, to_file='model-CNN.png', show_shapes=True, show_layer_names=True,\n",
        "    rankdir='TB', expand_nested=False, dpi=72\n",
        ")\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Image\n",
        "Image('model-CNN.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq6Bhdop4LlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics\n",
        "import itertools\n",
        "from packaging import version\n",
        "from six.moves import range\n",
        "import io\n",
        "\n",
        "def plot_to_image(figure):\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  return image\n",
        "\n",
        "def plot_confusion_matrix(cm, class_name):\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_name))\n",
        "  plt.xticks(tick_marks, class_name, rotation=45)\n",
        "  plt.yticks(tick_marks, class_name)\n",
        "\n",
        "  # Normalize the confusion matrix.\n",
        "  cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure\n",
        "\n",
        "# Clear out prior logging data.\n",
        "!rm -rf logs/image\n",
        "\n",
        "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Define the basic TensorBoard callback.\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
        "\n",
        "def log_confusion_matrix(epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "  test_pred_raw = model.predict(val_images)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "  # Calculate the confusion matrix.\n",
        "  cm = sklearn.metrics.confusion_matrix(val_labels, test_pred)\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  figure = plot_confusion_matrix(cm, class_name=class_name)\n",
        "  cm_image = plot_to_image(figure)\n",
        "\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  with file_writer_cm.as_default():\n",
        "    tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "\n",
        "# Define the per-epoch callback.\n",
        "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuLBQ98QUMW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('sparse_categorical_accuracy')>0.90 and logs.get('val_sparse_categorical_accuracy')>0.90):\n",
        "      print(\"\\n\\n\")\n",
        "      print(\"Akurasi telah mencapai nilai yang ditentukan!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxB8OUaj0faa",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "num_epoch = 300\n",
        "num_batch = 64\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), # menghitung crossentropy loss antara label dengan prediksi\n",
        "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()], # menghitung seberapa sering prediksi cocok dengan label integer\n",
        "    )\n",
        "\n",
        "# print(temp_train_images.shape, 'train_images')\n",
        "# print(temp_train_labels.shape, 'train_labels\\n')\n",
        "# print(val_images.shape, 'val_images')\n",
        "# print(val_labels.shape, 'val_labels\\n')\n",
        "\n",
        "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "mod = model.fit(\n",
        "    temp_train_images,\n",
        "    temp_train_labels,\n",
        "    epochs = num_epoch,\n",
        "    batch_size = num_batch,\n",
        "    verbose = 2,\n",
        "    callbacks = [tensorboard_callback, cm_callback, callbacks],\n",
        "    validation_data = (val_images, val_labels)\n",
        "    )\n",
        "\n",
        "# model.save_weights(\"skripsi_cnn.h5\")\n",
        "\n",
        "model.save(\"model_skripsi.h5\")\n",
        "\n",
        "# %tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylHybrS6CR2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start TensorBoard.\n",
        "%tensorboard --logdir logs/image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj1OobGkbbQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(mod.history.keys())\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Nilai Akurasi')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.plot(mod.history['sparse_categorical_accuracy'], 'tab:green')\n",
        "plt.plot(mod.history['val_sparse_categorical_accuracy'], 'tab:orange')\n",
        "plt.legend(['sparse_categorical_accuracy', 'validation_accuracy'], loc='upper left')\n",
        "plt.grid(b=True, which='major', color='#D1D1D1', linestyle='-')\n",
        "# plt.tight_layout()\n",
        "# plt.savefig(\"acc.png\")\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Nilai Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend([ 'loss'], loc='upper right')\n",
        "plt.plot(mod.history['loss'], 'tab:green')\n",
        "plt.plot(mod.history['val_loss'], 'tab:orange')\n",
        "plt.legend(['loss', 'validation_loss'], loc='upper left')\n",
        "plt.grid(b=True, which='major', color='#D1D1D1', linestyle='-')\n",
        "# plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"data-training.png\")\n",
        "\n",
        "plt.suptitle('Hasil Penilaian Akurasi dan Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKwz87vmeQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Accuracy')\n",
        "# plt.figure(figsize=(18, 6))\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.plot(mod.history['sparse_categorical_accuracy'], 'tab:green')\n",
        "plt.plot(mod.history['val_sparse_categorical_accuracy'], 'tab:orange')\n",
        "plt.legend(['sparse_categorical_accuracy', 'validation_accuracy'], loc='upper left')\n",
        "plt.grid(b=True, which='major', color='#D1D1D1', linestyle='-')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"acc.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXBg1Nv6ewfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend([ 'loss'], loc='upper right')\n",
        "plt.plot(mod.history['loss'], 'tab:green')\n",
        "plt.plot(mod.history['val_loss'], 'tab:orange')\n",
        "plt.legend(['loss', 'validation_loss'], loc='upper left')\n",
        "plt.grid(b=True, which='major', color='#D1D1D1', linestyle='-')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"loss.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9KPx8gybbeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(np.argmax(model.predict(val_images)))\n",
        "# print('Image Class :', model.predict_classes(val_images))\n",
        "# print(len(model.predict_classes(val_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTiPdo0m_HM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(val_images, val_labels, verbose=2)\n",
        "\n",
        "print('Test loss =', score[0])\n",
        "print('Test accuracy =', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI9NNKocmiER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# print (classification_report(val_labels, test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRdLbM2Lbihk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "unggah_data_test = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQhjDP5wbi85",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "eval_images = [preprocess_adaptive_gaussian(load_image(file)) for file in unggah_data_test.keys()]\n",
        "eval_model = tf.keras.Sequential(layers)\n",
        "\n",
        "# eval_model.load_weights(\"model_kulit_skripsi.h5\")\n",
        "eval_model.load_weights(\"model_skripsi.h5\")\n",
        "\n",
        "eval_predictions = eval_model.predict(np.expand_dims(eval_images, axis=-1))\n",
        "print(type(eval_predictions))\n",
        "\n",
        "cols = 6\n",
        "rows = np.ceil(len(eval_images) / cols)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(cols * 6, rows * 6)\n",
        "\n",
        "for i in range(len(eval_images)):\n",
        "    \n",
        "    print(np.argmax(eval_predictions[i]))\n",
        "    print(eval_predictions[i])\n",
        "\n",
        "    plt.subplot(rows, cols, i+1)\n",
        "    plt.imshow(eval_images[i], cmap=\"gray\")\n",
        "    \n",
        "    judul = ''\n",
        "    if (np.argmax(eval_predictions[i]) == 0) :\n",
        "        kelas = 'Sheep'\n",
        "    elif (np.argmax(eval_predictions[i]) == 1):\n",
        "        kelas = 'Synthetic'\n",
        "    elif (np.argmax(eval_predictions[i]) == 2):\n",
        "        kelas = 'Goat'\n",
        "    else:\n",
        "        kelas = 'Cow'\n",
        "    \n",
        "    plt.title(kelas)\n",
        "    plt.axis('on')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}